{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0899005e-01f4-4bfa-868b-3cfeaaf406d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset \n",
    "import torch.nn.functional as F \n",
    "import numpy as np \n",
    "import torch.optim as optim \n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d466528c-a619-4935-8493-c7ad30d76fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Data\n",
    "df = pd.read_excel(r'C:â€¦\\Iris_dataset.xlsx') \n",
    "print('Take a look at sample from the dataset:') \n",
    "print(df.head()) \n",
    "\n",
    "# Let's verify if our data is balanced and what types of species we have  \n",
    "print('\\nOur dataset is balanced and has the following values to predict:') \n",
    "print(df['Iris_Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b54b7-f2e1-45c3-bd5a-d9475c209f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Iris species into numeric types: Iris-setosa=0, Iris-versicolor=1, Iris-virginica=2.  \n",
    "labels = {'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2} \n",
    "df['IrisType_num'] = df['Iris_Type']   # Create a new column \"IrisType_num\" \n",
    "df.IrisType_num = [labels[item] for item in df.IrisType_num]  # Convert the values to numeric ones \n",
    "\n",
    "# Define input and output datasets \n",
    "input = df.iloc[:, 1:-2]            # We drop the first column and the two last ones.  \n",
    "output = df.loc[:, 'IrisType_num']   # Output Y is the last column  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81ed077-4d2b-4da3-9d07-84eb51bc9d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Input and Output data to Tensors and create a TensorDataset \n",
    "input = torch.Tensor(input.to_numpy())      # Create tensor of type torch.float32 \n",
    "print('\\nInput format: ', input.shape, input.dtype)     # Input format: torch.Size([150, 4]) torch.float32 \n",
    "output = torch.tensor(output.to_numpy())        # Create tensor type torch.int64  \n",
    "print('Output format: ', output.shape, output.dtype)  # Output format: torch.Size([150]) torch.int64 \n",
    "data = TensorDataset(input, output)    # Create a torch.utils.data.TensorDataset object for further data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3a349-cb75-42b8-8a87-8e61745667f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to Train, Validate and Test sets using random_split \n",
    "train_batch_size = 10        \n",
    "number_rows = len(input)    # The size of our dataset or the number of rows in excel table.  \n",
    "test_split = int(number_rows*0.3)  \n",
    "validate_split = int(number_rows*0.2) \n",
    "train_split = number_rows - test_split - validate_split     \n",
    "train_set, validate_set, test_set = random_split( \n",
    "    data, [train_split, validate_split, test_split])    \n",
    " \n",
    "# Create Dataloader to read the data within batch sizes and put into memory. \n",
    "train_loader = DataLoader(train_set, batch_size = train_batch_size, shuffle = True) \n",
    "validate_loader = DataLoader(validate_set, batch_size = 1) \n",
    "test_loader = DataLoader(test_set, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf977037-9063-47d6-b6b8-9d2b0a4896ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68463042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters \n",
    "input_size = list(input.shape)[1]   # = 4. The input depends on how many features we initially feed the model. In our case, there are 4 features for every predict value  \n",
    "learning_rate = 0.01 \n",
    "output_size = len(labels)           # The output is prediction results for three types of Irises.  \n",
    "\n",
    "\n",
    "# Define neural network \n",
    "class Network(nn.Module): \n",
    "   def __init__(self, input_size, output_size): \n",
    "       super(Network, self).__init__() \n",
    "        \n",
    "       self.layer1 = nn.Linear(input_size, 24) \n",
    "       self.layer2 = nn.Linear(24, 24) \n",
    "       self.layer3 = nn.Linear(24, output_size) \n",
    "\n",
    "\n",
    "   def forward(self, x): \n",
    "       x1 = F.relu(self.layer1(x)) \n",
    "       x2 = F.relu(self.layer2(x1)) \n",
    "       x3 = self.layer3(x2) \n",
    "       return x3 \n",
    " \n",
    "# Instantiate the model \n",
    "model = Network(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ced033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your execution device \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "print(\"The model will be running on\", device, \"device\\n\") \n",
    "model.to(device)    # Convert model parameters and buffers to CPU or Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the model \n",
    "def saveModel(): \n",
    "    path = \"./NetModel.pth\" \n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b416c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function \n",
    "def train(num_epochs): \n",
    "    best_accuracy = 0.0 \n",
    "     \n",
    "    print(\"Begin training...\") \n",
    "    for epoch in range(1, num_epochs+1): \n",
    "        running_train_loss = 0.0 \n",
    "        running_accuracy = 0.0 \n",
    "        running_vall_loss = 0.0 \n",
    "        total = 0 \n",
    " \n",
    "        # Training Loop \n",
    "        for data in train_loader: \n",
    "        #for data in enumerate(train_loader, 0): \n",
    "            inputs, outputs = data  # get the input and real species as outputs; data is a list of [inputs, outputs] \n",
    "            optimizer.zero_grad()   # zero the parameter gradients          \n",
    "            predicted_outputs = model(inputs)   # predict output from the model \n",
    "            train_loss = loss_fn(predicted_outputs, outputs)   # calculate loss for the predicted output  \n",
    "            train_loss.backward()   # backpropagate the loss \n",
    "            optimizer.step()        # adjust parameters based on the calculated gradients \n",
    "            running_train_loss +=train_loss.item()  # track the loss value \n",
    " \n",
    "        # Calculate training loss value \n",
    "        train_loss_value = running_train_loss/len(train_loader) \n",
    " \n",
    "        # Validation Loop \n",
    "        with torch.no_grad(): \n",
    "            model.eval() \n",
    "            for data in validate_loader: \n",
    "               inputs, outputs = data \n",
    "               predicted_outputs = model(inputs) \n",
    "               val_loss = loss_fn(predicted_outputs, outputs) \n",
    "             \n",
    "               # The label with the highest value will be our prediction \n",
    "               _, predicted = torch.max(predicted_outputs, 1) \n",
    "               running_vall_loss += val_loss.item()  \n",
    "               total += outputs.size(0) \n",
    "               running_accuracy += (predicted == outputs).sum().item() \n",
    " \n",
    "        # Calculate validation loss value \n",
    "        val_loss_value = running_vall_loss/len(validate_loader) \n",
    "                \n",
    "        # Calculate accuracy as the number of correct predictions in the validation batch divided by the total number of predictions done.  \n",
    "        accuracy = (100 * running_accuracy / total)     \n",
    " \n",
    "        # Save the model if the accuracy is the best \n",
    "        if accuracy > best_accuracy: \n",
    "            saveModel() \n",
    "            best_accuracy = accuracy \n",
    "         \n",
    "        # Print the statistics of the epoch \n",
    "        print('Completed training batch', epoch, 'Training Loss is: %.4f' %train_loss_value, 'Validation Loss is: %.4f' %val_loss_value, 'Accuracy is %d %%' % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84069d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to test the model \n",
    "def test(): \n",
    "    # Load the model that we saved at the end of the training loop \n",
    "    model = Network(input_size, output_size) \n",
    "    path = \"NetModel.pth\" \n",
    "    model.load_state_dict(torch.load(path)) \n",
    "     \n",
    "    running_accuracy = 0 \n",
    "    total = 0 \n",
    " \n",
    "    with torch.no_grad(): \n",
    "        for data in test_loader: \n",
    "            inputs, outputs = data \n",
    "            outputs = outputs.to(torch.float32) \n",
    "            predicted_outputs = model(inputs) \n",
    "            _, predicted = torch.max(predicted_outputs, 1) \n",
    "            total += outputs.size(0) \n",
    "            running_accuracy += (predicted == outputs).sum().item() \n",
    " \n",
    "        print('Accuracy of the model based on the test set of', test_split ,'inputs is: %d %%' % (100 * running_accuracy / total))    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15afc4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train(num_epochs) \n",
    "print('Finished Training\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7eebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7323a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
