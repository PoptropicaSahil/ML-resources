{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### points to take care of now onwards\n1. Add PCA components\n1. Search how to make the NN deeper\n1. Get it on the GPU\n1. Plot training losses with the validation losses\n1. **use KFold CV**","metadata":{}},{"cell_type":"markdown","source":"# usual imports","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport gc\n\nimport matplotlib.pyplot as plt\nfrom scipy import stats# Imports\nimport torch\n\nimport torchvision\nimport torch.nn as nn\n\nimport torch.nn.functional as F\n\nfrom torch.utils.data import DataLoader, TensorDataset, random_split","metadata":{"papermill":{"duration":7.781864,"end_time":"2022-01-25T15:39:09.265726","exception":false,"start_time":"2022-01-25T15:39:01.483862","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-19T09:47:31.364364Z","iopub.execute_input":"2022-02-19T09:47:31.364943Z","iopub.status.idle":"2022-02-19T09:47:33.614402Z","shell.execute_reply.started":"2022-02-19T09:47:31.364841Z","shell.execute_reply":"2022-02-19T09:47:33.613671Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:47:33.616129Z","iopub.execute_input":"2022-02-19T09:47:33.616508Z","iopub.status.idle":"2022-02-19T09:47:33.777341Z","shell.execute_reply.started":"2022-02-19T09:47:33.616474Z","shell.execute_reply":"2022-02-19T09:47:33.776646Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:47:33.778692Z","iopub.execute_input":"2022-02-19T09:47:33.779143Z","iopub.status.idle":"2022-02-19T09:47:33.794038Z","shell.execute_reply.started":"2022-02-19T09:47:33.779107Z","shell.execute_reply":"2022-02-19T09:47:33.793056Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Import dataset","metadata":{"papermill":{"duration":0.015291,"end_time":"2022-01-25T15:39:09.296817","exception":false,"start_time":"2022-01-25T15:39:09.281526","status":"completed"},"tags":[]}},{"cell_type":"code","source":"n_features = 300\nfeatures = [f'f_{i}' for i in range(n_features)]\ntrain = pd.read_pickle('../input/ubiquant-market-prediction-half-precision-pickle/train.pkl')\ntrain.head(2)","metadata":{"papermill":{"duration":16.88418,"end_time":"2022-01-25T15:39:26.19638","exception":false,"start_time":"2022-01-25T15:39:09.3122","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-02-19T09:47:33.796537Z","iopub.execute_input":"2022-02-19T09:47:33.796918Z","iopub.status.idle":"2022-02-19T09:47:52.281219Z","shell.execute_reply.started":"2022-02-19T09:47:33.796882Z","shell.execute_reply":"2022-02-19T09:47:52.280535Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"inputs = train.drop(['target'], axis=1).values\ntargets = train[['target']].values\n\ninputs.shape, targets.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:47:52.282571Z","iopub.execute_input":"2022-02-19T09:47:52.283028Z","iopub.status.idle":"2022-02-19T09:48:00.088836Z","shell.execute_reply.started":"2022-02-19T09:47:52.282989Z","shell.execute_reply":"2022-02-19T09:48:00.088127Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### 80 % split number - just for splitting","metadata":{"execution":{"iopub.status.busy":"2022-02-12T07:05:50.018581Z","iopub.execute_input":"2022-02-12T07:05:50.020216Z","iopub.status.idle":"2022-02-12T07:05:50.028672Z","shell.execute_reply.started":"2022-02-12T07:05:50.020168Z","shell.execute_reply":"2022-02-12T07:05:50.027667Z"}}},{"cell_type":"code","source":"val_1 = int(0.8*inputs.shape[0])\nval_2 = int(0.2*inputs.shape[0])\nval_1, val_2","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:00.090144Z","iopub.execute_input":"2022-02-19T09:48:00.090494Z","iopub.status.idle":"2022-02-19T09:48:00.099221Z","shell.execute_reply.started":"2022-02-19T09:48:00.090455Z","shell.execute_reply":"2022-02-19T09:48:00.098349Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameters","metadata":{"execution":{"iopub.status.busy":"2022-02-12T07:05:50.030025Z","iopub.execute_input":"2022-02-12T07:05:50.030959Z","iopub.status.idle":"2022-02-12T07:05:50.04492Z","shell.execute_reply.started":"2022-02-12T07:05:50.030913Z","shell.execute_reply":"2022-02-12T07:05:50.043616Z"}}},{"cell_type":"code","source":"batch_size = 1000\nTARGET_COLUMN = 'target'\ninput_size=302\noutput_size=1","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:00.100773Z","iopub.execute_input":"2022-02-19T09:48:00.101222Z","iopub.status.idle":"2022-02-19T09:48:00.107009Z","shell.execute_reply.started":"2022-02-19T09:48:00.101182Z","shell.execute_reply":"2022-02-19T09:48:00.106173Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"del train\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:00.108389Z","iopub.execute_input":"2022-02-19T09:48:00.108856Z","iopub.status.idle":"2022-02-19T09:48:00.230318Z","shell.execute_reply.started":"2022-02-19T09:48:00.108818Z","shell.execute_reply":"2022-02-19T09:48:00.229504Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Convert to PyTorch dataset (DataLoader)","metadata":{"execution":{"iopub.status.busy":"2022-02-12T07:05:50.046326Z","iopub.execute_input":"2022-02-12T07:05:50.048467Z","iopub.status.idle":"2022-02-12T07:05:53.061696Z","shell.execute_reply.started":"2022-02-12T07:05:50.048424Z","shell.execute_reply":"2022-02-12T07:05:53.060279Z"}}},{"cell_type":"code","source":"dataset = TensorDataset(torch.tensor(inputs, dtype=torch.float32), torch.tensor(targets, dtype=torch.float32))\ntrain_ds, val_ds = random_split(dataset, [val_1, val_2])\n\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=False) # future predict karna hai na\nval_loader = DataLoader(val_ds, batch_size*2)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:00.232016Z","iopub.execute_input":"2022-02-19T09:48:00.232548Z","iopub.status.idle":"2022-02-19T09:48:02.736791Z","shell.execute_reply.started":"2022-02-19T09:48:00.232505Z","shell.execute_reply":"2022-02-19T09:48:02.736054Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"del train_ds, val_ds, dataset, inputs, targets\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:02.740078Z","iopub.execute_input":"2022-02-19T09:48:02.740371Z","iopub.status.idle":"2022-02-19T09:48:02.917299Z","shell.execute_reply.started":"2022-02-19T09:48:02.740336Z","shell.execute_reply":"2022-02-19T09:48:02.916545Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## GPU Utilities\n#### these will help later to get our models/dataloaders on the GPU!","metadata":{}},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:02.918694Z","iopub.execute_input":"2022-02-19T09:48:02.919153Z","iopub.status.idle":"2022-02-19T09:48:02.929431Z","shell.execute_reply.started":"2022-02-19T09:48:02.919114Z","shell.execute_reply":"2022-02-19T09:48:02.928766Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"#### Check if GPU is avaliable","metadata":{}},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:02.930736Z","iopub.execute_input":"2022-02-19T09:48:02.931124Z","iopub.status.idle":"2022-02-19T09:48:02.989134Z","shell.execute_reply.started":"2022-02-19T09:48:02.931084Z","shell.execute_reply":"2022-02-19T09:48:02.988387Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:02.990790Z","iopub.execute_input":"2022-02-19T09:48:02.991347Z","iopub.status.idle":"2022-02-19T09:48:03.001270Z","shell.execute_reply.started":"2022-02-19T09:48:02.991295Z","shell.execute_reply":"2022-02-19T09:48:03.000286Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### \"Push\" to the GPU","metadata":{}},{"cell_type":"code","source":"train_loader = DeviceDataLoader(train_loader, device)\nval_loader = DeviceDataLoader(train_loader, device)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:03.002674Z","iopub.execute_input":"2022-02-19T09:48:03.003035Z","iopub.status.idle":"2022-02-19T09:48:03.015261Z","shell.execute_reply.started":"2022-02-19T09:48:03.002998Z","shell.execute_reply":"2022-02-19T09:48:03.014512Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# This is the heart of the Neural Network!\n**feel free to edit the layers anytime**","metadata":{}},{"cell_type":"markdown","source":"A lot of credit for this goes to \n1. Akash N S, for his Jovian.ai Course. This notebook specially makes use of functions from here https://jovian.ai/aakashns-6l3/deep-learning-project-live\n1. @Pytonash's Recent notebook using Keras, and a very similar structure - End to end simple and powerful DNN with LeakyReLU - https://www.kaggle.com/pythonash/end-to-end-simple-and-powerful-dnn-with-leakyrelu\n3. General answers from StackOverflow like this one, which helps to make out where should features be placed and ordered https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout","metadata":{}},{"cell_type":"code","source":"class My_Kaggle_Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        # Activation functions have been chosen either as SiLU (called as Swish in Keras), and LeakyReLU\n        # I have used them in alternate, please comment if this is a good practice or not!\n        self.layers = nn.Sequential(nn.Linear(input_size, 64), \n                                    nn.BatchNorm1d(64), \n                                    nn.SiLU(), \n                                    \n                                    nn.Linear(64, 128), \n                                    nn.BatchNorm1d(128), \n                                    nn.LeakyReLU(0.1), \n                                    nn.Dropout(0.1),\n                                    \n                                    nn.Linear(128, 256), \n                                    nn.BatchNorm1d(256), \n                                    nn.SiLU(), \n                                    nn.Dropout(0.1),\n                                    \n                                    nn.Linear(256, 512), \n                                    nn.BatchNorm1d(512), \n                                    nn.LeakyReLU(0.1),\n                                    nn.Dropout(0.3), \n                                    \n                                    nn.Linear(512, 256), \n                                    nn.BatchNorm1d(256), \n                                    nn.SiLU(),\n                                    nn.Dropout(0.1),\n                                    \n                                    nn.Linear(256, 128), \n                                    nn.BatchNorm1d(128), \n                                    nn.LeakyReLU(0.1),\n                                    nn.Dropout(0.1),\n                                    \n                                    nn.Linear(128, 8), \n                                    nn.BatchNorm1d(8), \n                                    nn.SiLU(), \n                                    nn.Dropout(0.3),\n                                    \n                                    nn.Linear(8, 1) )\n    \n        \n    def forward(self, x):\n        return self.layers(x)\n    \n    def training_step(self, batch):\n        torch.cuda.empty_cache()\n        gc.collect()\n        inputs, targets = batch \n        inputs.to(device)\n        targets.to(device)\n        \n        out = self(inputs)                 # Generate predictions\n        loss = F.mse_loss(out, targets)    # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        torch.cuda.empty_cache()\n        gc.collect()\n        inputs, targets = batch \n        inputs.to(device)\n        targets.to(device)\n        \n        out = self(inputs)                 # Generate predictions\n        loss = F.mse_loss(out, targets)    # Calculate loss\n        return {'val_loss': loss.detach()}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        return {'val_loss': epoch_loss.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}\".format(epoch, result['train_loss'], result['val_loss']))\n    \nmodel = My_Kaggle_Model()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:03.016739Z","iopub.execute_input":"2022-02-19T09:48:03.017045Z","iopub.status.idle":"2022-02-19T09:48:03.054298Z","shell.execute_reply.started":"2022-02-19T09:48:03.017006Z","shell.execute_reply":"2022-02-19T09:48:03.053625Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# shift model to GPU\nmodel = to_device(model, device)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:03.055650Z","iopub.execute_input":"2022-02-19T09:48:03.055924Z","iopub.status.idle":"2022-02-19T09:48:05.926514Z","shell.execute_reply.started":"2022-02-19T09:48:03.055890Z","shell.execute_reply":"2022-02-19T09:48:05.925643Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Simple functions for evaluating and fitting","metadata":{}},{"cell_type":"code","source":"def evaluate(model, val_loader):\n    model.eval()  # Setting to eval mode makes sure that dropouts are 'frozen'\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train() # Setting to train mode\n        train_losses = []\n        \n        for batch in train_loader:\n            torch.cuda.empty_cache()\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:05.931104Z","iopub.execute_input":"2022-02-19T09:48:05.933206Z","iopub.status.idle":"2022-02-19T09:48:05.946730Z","shell.execute_reply.started":"2022-02-19T09:48:05.933166Z","shell.execute_reply":"2022-02-19T09:48:05.945283Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### Checking if everything is on the GPU","metadata":{}},{"cell_type":"code","source":"train_loader.device, val_loader.device","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:05.948362Z","iopub.execute_input":"2022-02-19T09:48:05.953912Z","iopub.status.idle":"2022-02-19T09:48:05.973699Z","shell.execute_reply.started":"2022-02-19T09:48:05.953876Z","shell.execute_reply":"2022-02-19T09:48:05.972490Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"type(model)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:05.975117Z","iopub.execute_input":"2022-02-19T09:48:05.975679Z","iopub.status.idle":"2022-02-19T09:48:05.987479Z","shell.execute_reply.started":"2022-02-19T09:48:05.975643Z","shell.execute_reply":"2022-02-19T09:48:05.986747Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model.state_dict()['layers.0.weight']","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:05.988704Z","iopub.execute_input":"2022-02-19T09:48:05.989487Z","iopub.status.idle":"2022-02-19T09:48:06.078621Z","shell.execute_reply.started":"2022-02-19T09:48:05.989442Z","shell.execute_reply":"2022-02-19T09:48:06.077946Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"*observe how the weights are also on the GPU, so nice to see!*","metadata":{}},{"cell_type":"markdown","source":"# Train!","metadata":{}},{"cell_type":"code","source":"learning_rate = 1e-2","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:06.081300Z","iopub.execute_input":"2022-02-19T09:48:06.084108Z","iopub.status.idle":"2022-02-19T09:48:06.089181Z","shell.execute_reply.started":"2022-02-19T09:48:06.084069Z","shell.execute_reply":"2022-02-19T09:48:06.088336Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:06.090250Z","iopub.execute_input":"2022-02-19T09:48:06.090998Z","iopub.status.idle":"2022-02-19T09:48:06.281031Z","shell.execute_reply.started":"2022-02-19T09:48:06.090961Z","shell.execute_reply":"2022-02-19T09:48:06.277872Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = fit(30, learning_rate, model, train_loader, val_loader)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T09:48:06.282316Z","iopub.execute_input":"2022-02-19T09:48:06.283103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !/opt/bin/nvidia-smi\n# optional function to check if you have a GPU or not","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train for more with lower learning rate\n%%time\nhistory = fit(10, 5e-5, model.cuda, train_loader, val_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');\n    \nplot_losses(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**it is a good practice to check this curve and determine if our model is overfitting or not**","metadata":{}},{"cell_type":"markdown","source":"### Record results","metadata":{}},{"cell_type":"code","source":"history[-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(model, train_loader), evaluate(model, val_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### important to save the model!","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), 'my_trained_model.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# time to make predictions!","metadata":{}},{"cell_type":"code","source":"val_ds[1][0].shape, val_ds[1][1].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Simple function to predict","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache() # just to clear some GPU cache memory","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### lets see if it works on the train loader (it should!)","metadata":{}},{"cell_type":"code","source":"for batch in train_loader:\n    model.eval() # not strictly necessary to put it in eval mode, because we took adequate care earlier\n    data, target = batch\n    print('data.shape', data.shape)\n    print('data.device', data.device)\n    preds = model(data)\n    print('preds.shape', preds.shape)\n    break # this is just for checking, so I break after one round","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### and on the valid loader","metadata":{}},{"cell_type":"code","source":"for batch in val_loader:\n    model.eval()\n    data, target = batch\n    print('data.shape', data.shape)\n    print('data.device', data.device)\n    preds = model(data)\n    print('preds.shape', preds.shape)\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds[:5], target[:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission Time!","metadata":{}},{"cell_type":"markdown","source":"### simple function to predict on the test dataframe","metadata":{}},{"cell_type":"code","source":"cols_order = ['investment_id' , 'time_id'] + features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_for_test_data(test_data):\n    test_ds = TensorDataset(torch.tensor(test_data.values, dtype=torch.float32))\n    submission_try = []\n    \n    for x in test_ds:\n        model.eval()\n        pred = model(x)\n        submission_try.append(pred)\n        print(\"Prediction:\", pred)\n        \n    submission_values = [float(i.detach()) for i in submission_try]\n    return submission_values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### submit off!\nCredits to @Melanie7744 for informing about the submission API. Here is the link to her work https://www.kaggle.com/melanie7744/understanding-the-submission-api-for-newbies","metadata":{}},{"cell_type":"code","source":"import ubiquant\nenv = ubiquant.make_env()   # initialize the environment\niter_test = env.iter_test()    # an iterator which loops over the test set and sample submission\nfor (test_df, sample_prediction_df) in iter_test:\n    \n    print(\"test_df as loaded by the API\")\n    display(test_df.head(), test_df.shape)\n    #display(sample_prediction_df.head(), sample_prediction_df.shape)\n    \n    # here you need to modify test_df to match the training data\n    test_df['time_id'] = test_df.row_id.str.split(\"_\", expand=True)[0].astype(\"int16\") #re-create time_id\n    test_df = test_df[cols_order]  \n    print(\"test_df after selecting/creating the features the model was trained with\")\n    display(test_df.head(), test_df.shape)\n    \n    # Call our function to make predictions\n    predictions = predict_for_test_data(test_df)\n    sample_prediction_df['target'] = predictions  # make your predictions here\n    env.predict(sample_prediction_df)   # register your predictions\n    \n    # print(\"Predictions for this time_id\")\n    # display(sample_prediction_df)\n    # print(\"-----------time_id finished-----------\\n\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}